{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boom/anaconda3/envs/marigold/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of UNet2DConditionModel were not initialized from the model checkpoint at ./stable-diffusion-v1-5 and are newly initialized because the shapes did not match:\n",
      "- conv_in.weight: found shape torch.Size([320, 4, 3, 3]) in the checkpoint and torch.Size([320, 8, 3, 3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "\n",
    "from diffusers import (\n",
    "    DiffusionPipeline,\n",
    "    DDIMScheduler,\n",
    "    DDPMScheduler,\n",
    "    UNet2DConditionModel,\n",
    "    AutoencoderKL,\n",
    ")\n",
    "from diffusers.utils import BaseOutput\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "num_train_timesteps=300\n",
    "unet = UNet2DConditionModel(\n",
    ").from_pretrained('./stable-diffusion-v1-5',\n",
    "                  subfolder=\"unet\",\n",
    "                  in_channels=8,\n",
    "                  out_channels=4,\n",
    "                  low_cpu_mem_usage=False,\n",
    "                  ignore_mismatched_sizes=True,\n",
    "                  local_files_only = True)\n",
    "vae = AutoencoderKL().from_pretrained('./stable-diffusion-v1-5',subfolder=\"vae\")\n",
    "scheduler = DDIMScheduler(num_train_timesteps=1000).from_pretrained('./stable-diffusion-v1-5',subfolder=\"scheduler\")\n",
    "tokenizer = CLIPTokenizer.from_pretrained('./stable-diffusion-v1-5',subfolder=\"tokenizer\")\n",
    "text_encoder = CLIPTextModel.from_pretrained('./stable-diffusion-v1-5',subfolder=\"text_encoder\")\n",
    "# device = 'cuda'\n",
    "# vae.requires_grad_(False)\n",
    "# unet.requires_grad_(True)\n",
    "# text_encoder.requires_grad_(False)\n",
    "# text_encoder.text_model.embeddings.token_embedding.requires_grad_(False)\n",
    "# # tokenizer.requires_grad_(False)\n",
    "\n",
    "# vae.eval()\n",
    "# text_encoder.text_model.embeddings.token_embedding.eval()\n",
    "# text_encoder.eval()\n",
    "# unet.train()\n",
    "\n",
    "# vae.to(device)\n",
    "# unet.to(device)\n",
    "class FinetuneUnet(nn.Module):\n",
    "    rgb_latent_scale_factor = 0.18215\n",
    "    depth_latent_scale_factor = 0.18215\n",
    "    def __init__(\n",
    "            self,\n",
    "            unet: unet,\n",
    "            vae: AutoencoderKL,\n",
    "            scheduler: DDIMScheduler,\n",
    "            text_encoder: CLIPTextModel,\n",
    "            tokenizer: CLIPTokenizer,\n",
    "    ):\n",
    "        super(FinetuneUnet, self).__init__()\n",
    "        self.unet = unet\n",
    "        self.vae = vae\n",
    "        self.scheduler = scheduler\n",
    "        self.text_encoder = text_encoder\n",
    "        self.tokenizer = tokenizer\n",
    "        self.empty_text_embed = None\n",
    "\n",
    "    def __encode_empty_text(self):\n",
    "        \"\"\"\n",
    "        Encode text embedding for empty prompt\n",
    "        \"\"\"\n",
    "        prompt = \"\"\n",
    "        text_inputs = self.tokenizer(\n",
    "            \"\",\n",
    "            padding=\"do_not_pad\",\n",
    "            max_length=self.tokenizer.model_max_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        text_input_ids = text_inputs.input_ids.to(self.text_encoder.device)\n",
    "        self.empty_text_embed = self.text_encoder(text_input_ids)[0].to(torch.float32)\n",
    "\n",
    "    def encode_3c(self, render: torch.Tensor) -> torch.Tensor:\n",
    "        # encode\n",
    "        h = self.vae.encoder(render)\n",
    "        moments = self.vae.quant_conv(h)\n",
    "        mean, logvar = torch.chunk(moments, 2, dim=1)\n",
    "        # scale latent\n",
    "        render_latent = mean * self.rgb_latent_scale_factor\n",
    "        return render_latent\n",
    "\n",
    "    def forward(self,render_depth_normal_latent):\n",
    "        device = render_depth_normal_latent.device\n",
    "\n",
    "        render_latent = render_depth_normal_latent[:,0:4,:,:]\n",
    "        depth_normal_latent = render_depth_normal_latent[:,4:8,:,:]\n",
    "\n",
    "        # noise is 4 channel\n",
    "        noise = torch.randn((render_latent.shape[0],4,render_latent.shape[2],render_latent.shape[3]), device=device) # noise for depth_normal_latent\n",
    "        bs = render_latent.shape[0]\n",
    "        timesteps = torch.randint(\n",
    "            0, self.scheduler.config.num_train_timesteps, (bs,), device=device,\n",
    "            dtype=torch.int64\n",
    "        )\n",
    "        # Add noise to the clean images according to the noise magnitude at each timestep\n",
    "        noisy_depth_normal = self.scheduler.add_noise(depth_normal_latent, noise, timesteps)\n",
    "\n",
    "        # empty text embedding\n",
    "        if self.empty_text_embed is None:\n",
    "            self.__encode_empty_text()\n",
    "        batch_empty_text_embed = self.empty_text_embed.repeat(\n",
    "            (render_latent.shape[0], 1, 1)\n",
    "        )  # [B, 2, 1024]\n",
    "\n",
    "        unet_input = torch.cat([render_latent,noisy_depth_normal],dim=1)\n",
    "        pred_noise = self.unet(unet_input,timesteps,encoder_hidden_states=batch_empty_text_embed).sample\n",
    "        return pred_noise, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet2DConditionModel(\n",
       "  (conv_in): Conv2d(8, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (time_proj): Timesteps()\n",
       "  (time_embedding): TimestepEmbedding(\n",
       "    (linear_1): LoRACompatibleLinear(in_features=320, out_features=1280, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): LoRACompatibleConv(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): LoRACompatibleConv(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-2): 3 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): LoRACompatibleConv(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=768, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=768, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): LoRACompatibleConv(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): LoRACompatibleConv(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): LoRACompatibleConv(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): CrossAttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=768, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=768, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): LoRACompatibleConv(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1-2): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): LoRACompatibleConv(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): UNetMidBlock2DCrossAttn(\n",
       "    (attentions): ModuleList(\n",
       "      (0): Transformer2DModel(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn1): Attention(\n",
       "              (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): Attention(\n",
       "              (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): LoRACompatibleLinear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): ModuleList(\n",
       "                (0): GEGLU(\n",
       "                  (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0-1): 2 x ResnetBlock2D(\n",
       "        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "  (conv_act): SiLU()\n",
       "  (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "vae.requires_grad_(False)\n",
    "unet.requires_grad_(True)\n",
    "text_encoder.requires_grad_(False)\n",
    "text_encoder.text_model.embeddings.token_embedding.requires_grad_(False)\n",
    "\n",
    "vae.eval()\n",
    "text_encoder.text_model.embeddings.token_embedding.eval()\n",
    "text_encoder.eval()\n",
    "unet.train()\n",
    "\n",
    "vae.to(device)\n",
    "unet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = FinetuneUnet(unet=unet, vae=vae, scheduler=scheduler, text_encoder=text_encoder, tokenizer=tokenizer)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(612, 8, 60, 80)\n",
      "(612, 8, 60, 80)\n",
      "(612, 8, 60, 80)\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "render = np.load('./data_label_latent.npy').astype(np.float32)\n",
    "print(render.shape)\n",
    "# render = render.transpose(0, 3, 1, 2)\n",
    "print(render.shape)\n",
    "# data = render[0:5000]\n",
    "data = render\n",
    "# data = np.concatenate([render,render,render],axis=1)\n",
    "print(data.shape)\n",
    "print(type(data[0][1][1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306, torch.Size([2, 8, 60, 80]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=data,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "len(loader), next(iter(loader)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show(images,save=False,name='default'):\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    if type(images) == torch.Tensor:\n",
    "        images = images.to('cpu').detach().numpy()\n",
    "\n",
    "    images = images[:50]\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        image = image.transpose(1, 2, 0)\n",
    "        # image = (image + 1) / 2\n",
    "        if image.shape[2] == 1:\n",
    "            plt.subplot(5, 10, i + 1)\n",
    "            plt.imshow(image,cmap='gray')\n",
    "            plt.axis('off')\n",
    "            \n",
    "        else:\n",
    "            plt.subplot(5, 10, i + 1)\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "    if save:\n",
    "        plt.savefig(f'{name}.pdf') \n",
    "    plt.show()\n",
    "\n",
    "def show_error_map(pred, gd, save=False,name='default'):\n",
    "    # Ensure the tensors have the same shape\n",
    "    assert pred.shape == gd.shape, \"Input tensors must have the same shape\"\n",
    "    pred = pred.mean(dim=1, keepdim=True)\n",
    "    gd = gd.mean(dim=1, keepdim=True)\n",
    "    # Calculate the absolute difference between the prediction and ground truth\n",
    "    error_map = torch.abs(pred - gd) * 10\n",
    "    show(error_map,save,name)\n",
    "show(next(iter(loader))[:,1:2,:,:],save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 60, 80])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "def ssim_loss(data,pred):\n",
    "    ssim_values = 0.0  # Initialize a variable to accumulate SSIM values\n",
    "    # Loop through the batch of images\n",
    "    data = data.detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    pred = pred.detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    for i in range(data.shape[0]):\n",
    "        # Calculate SSIM between original and reconstructed image\n",
    "        # ssim_val = ssim(upscaled_img1, upscaled_img2, multichannel=True, channel_axis=2)\n",
    "        ssim_val = ssim(data[i], pred[i], multichannel=True, data_range=data[i].max()-data[i].min())\n",
    "        ssim_values += ssim_val\n",
    "    \n",
    "    # Compute the average SSIM across all images in the batch\n",
    "    average_ssim = ssim_values / data.shape[0]\n",
    "    loss = 1 - average_ssim\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.metrics import structural_similarity as ssim\n",
    "# def train():\n",
    "#     criterion = torch.nn.L1Loss()\n",
    "#     optimizer = torch.optim.AdamW(model.parameters(),\n",
    "#                                   lr=1e-5,                   \n",
    "#                                   weight_decay=1e-4)\n",
    "#     model.to(device)\n",
    "#     model.train()\n",
    "\n",
    "#     accu_loss  = 0\n",
    "#     total_loss = 0 \n",
    "#     for epoch in range(2000):\n",
    "#         for i, data in enumerate(loader):\n",
    "#             pred_noise, noise = model(data.to(device))\n",
    "#             loss = criterion(pred_noise, noise)\n",
    "#             loss = loss + 5 * ssim_loss(pred_noise, noise)\n",
    "#             accu_loss += loss\n",
    "#             total_loss += loss\n",
    "#             if (i+1) % 8 == 0:\n",
    "#                 accu_loss.backward()\n",
    "#                 torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#                 optimizer.step()\n",
    "#                 optimizer.zero_grad()\n",
    "#                 print(f\"Epoch {epoch + 1}, Batch {i + 1}/{len(loader)}, Loss: {accu_loss.item():.4f}\", end='\\r')\n",
    "#                 accu_loss = 0\n",
    "#             torch.cuda.empty_cache()\n",
    "#         if epoch % 1 == 0:\n",
    "#             print(epoch, total_loss)\n",
    "#             total_loss = 0\n",
    "#             # model.eval()\n",
    "#             # show(generate(10, device))\n",
    "#             # model.train()\n",
    "#             torch.save(unet.state_dict(), './unet_finetune.pth')\n",
    "\n",
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 74.72758718207479 0.07472758718207478\n",
      "Epoch 2, Batch 284/306, Loss: 0.1151\r"
     ]
    }
   ],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "def train():\n",
    "    criterion = torch.nn.L1Loss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                                  lr=1e-5,                   \n",
    "                                  weight_decay=1e-4)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    loss_sum = 0\n",
    "    for epoch in range(1000):\n",
    "        for i, data in enumerate(loader):\n",
    "            pred_noise, noise = model(data.to(device))\n",
    "            loss = criterion(pred_noise, noise)\n",
    "            # loss = loss + 1 * ssim_loss(pred_noise, noise)\n",
    "\n",
    "            loss.backward()\n",
    "            loss_sum += loss.item()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            print(f\"Epoch {epoch + 1}, Batch {i + 1}/{len(loader)}, Loss: {loss.item():.4f}\", end='\\r')\n",
    "        if epoch % 1 == 0:\n",
    "            print(epoch, loss_sum, loss_sum/1000)\n",
    "            loss_sum = 0\n",
    "            # model.eval()\n",
    "            #show(generate(10, device))\n",
    "            # model.train()\n",
    "            torch.save(model.state_dict(), './unet_finetune_sl.pth')\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssim_values = 0.0  # Initialize a variable to accumulate SSIM values\n",
    "            # # Loop through the batch of images\n",
    "            # data = data.detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "            # pred = pred.detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "            # for i in range(data.shape[0]):\n",
    "            #     # Calculate SSIM between original and reconstructed image\n",
    "                \n",
    "            #     # ssim_val = ssim(upscaled_img1, upscaled_img2, multichannel=True, channel_axis=2)\n",
    "            #     ssim_val = ssim(data[i], pred[i], multichannel=True)\n",
    "            #     ssim_values += ssim_val\n",
    "            \n",
    "            # # Compute the average SSIM across all images in the batch\n",
    "            # average_ssim = ssim_values / data.shape[0]\n",
    "            # loss = 1 * loss + 0 * (1 - average_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = torch.nn.L1Loss()\n",
    "# optimizer = torch.optim.AdamW(model.parameters(),\n",
    "#                                   lr=5e-5,\n",
    "#                                   weight_decay=1e-4)\n",
    "# def train():\n",
    "#     for epoch in range(2000):\n",
    "#         for i, data in enumerate(loader):\n",
    "            \n",
    "#             pred_noise, noise = model(data.to(device))\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             loss = criterion(pred_noise, noise)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             print(f\"Epoch {epoch + 1}, Batch {i + 1}/{len(loader)}, Loss: {loss.item():.4f}\", end='\\r')\n",
    "#         torch.save(model.state_dict(), './unet_finetune.pth')\n",
    "\n",
    "\n",
    "# train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------TEST CODE -----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to(device)\n",
    "# model.eval()\n",
    "# unet = model.unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.shape)\n",
    "# data = data[0:4,:,:,:]\n",
    "# data = torch.from_numpy(data).to(device)\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_noise, noise = model(data)\n",
    "# print(pred_noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth_latent = pred_noise[:,0:4,:,:]\n",
    "# depth_latent.shape\n",
    "# output_tensor = torch.mean(depth_latent, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rgb_latent_scale_factor = 0.18215\n",
    "# depth_latent_scale_factor = 0.18215\n",
    "# def encode_3c(render: torch.Tensor) -> torch.Tensor:\n",
    "#         # encode\n",
    "#         h = vae.encoder(render)\n",
    "#         moments = vae.quant_conv(h)\n",
    "#         mean, logvar = torch.chunk(moments, 2, dim=1)\n",
    "#         # scale latent\n",
    "#         render_latent = mean * rgb_latent_scale_factor\n",
    "#         return render_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render = np.load('./render.npy').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(render.shape)\n",
    "# render = render.transpose(0,3,1,2)\n",
    "# render = torch.from_numpy(render).cuda()\n",
    "# print(render.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae = vae.cuda()\n",
    "# out = encode_3c(render[3:7])\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# data_all = np.empty((5400,4,32,32),np.float32)\n",
    "# for i in tqdm(range(data_all.shape[0])):\n",
    "#     out = encode_3c(render[i:i+1])\n",
    "#     data_all[i] = out.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_depth_normal_latent = np.concatenate([data_all,data_all,data_all],axis=1)\n",
    "# render_depth_normal_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./render_depth_normal_latet.npy',render_depth_normal_latent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marigold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
